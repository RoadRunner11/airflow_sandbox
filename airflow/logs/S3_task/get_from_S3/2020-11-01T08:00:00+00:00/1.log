[2020-11-01 18:53:36,907] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: S3_task.get_from_S3 2020-11-01T08:00:00+00:00 [queued]>
[2020-11-01 18:53:36,962] {taskinstance.py:670} INFO - Dependencies all met for <TaskInstance: S3_task.get_from_S3 2020-11-01T08:00:00+00:00 [queued]>
[2020-11-01 18:53:36,963] {taskinstance.py:880} INFO - 
--------------------------------------------------------------------------------
[2020-11-01 18:53:36,963] {taskinstance.py:881} INFO - Starting attempt 1 of 4
[2020-11-01 18:53:36,963] {taskinstance.py:882} INFO - 
--------------------------------------------------------------------------------
[2020-11-01 18:53:36,995] {taskinstance.py:901} INFO - Executing <Task(PythonOperator): get_from_S3> on 2020-11-01T08:00:00+00:00
[2020-11-01 18:53:36,999] {standard_task_runner.py:54} INFO - Started process 25468 to run task
[2020-11-01 18:53:37,083] {standard_task_runner.py:77} INFO - Running: ['airflow', 'run', 'S3_task', 'get_from_S3', '2020-11-01T08:00:00+00:00', '--job_id', '16', '--pool', 'default_pool', '--raw', '-sd', '/home/akorede/Documents/airflow_sandbox/airflow/dags/s3_dag.py', '--cfg_path', '/tmp/tmpcukc5o7u']
[2020-11-01 18:53:37,091] {standard_task_runner.py:78} INFO - Job 16: Subtask get_from_S3
[2020-11-01 18:53:37,238] {logging_mixin.py:112} INFO - Running %s on host %s <TaskInstance: S3_task.get_from_S3 2020-11-01T08:00:00+00:00 [running]> akorede-VirtualBox
[2020-11-01 18:53:39,773] {python_operator.py:114} INFO - Done. Returned value was: None
[2020-11-01 18:53:39,805] {taskinstance.py:1070} INFO - Marking task as SUCCESS.dag_id=S3_task, task_id=get_from_S3, execution_date=20201101T080000, start_date=20201101T175336, end_date=20201101T175339
[2020-11-01 18:53:41,870] {local_task_job.py:102} INFO - Task exited with return code 0
